"""æ•°æ®ç®¡ç†æ¨¡å— - æœ¬åœ°ç¼“å­˜å’Œå¢é‡æ›´æ–°"""
import os
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import time

from data_fetcher import get_stock_data
from config import START_DATE, END_DATE

# æ•°æ®å­˜å‚¨ç›®å½•
DATA_DIR = Path("./data_cache")
DB_FILE = DATA_DIR / "stock_data.db"
CACHE_DIR = DATA_DIR / "cache"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
DATA_DIR.mkdir(exist_ok=True)
CACHE_DIR.mkdir(exist_ok=True)

class DataManager:
    """æ•°æ®ç®¡ç†ç±» - å¤„ç†æœ¬åœ°ç¼“å­˜å’Œç½‘ç»œè·å–"""

    def __init__(self):
        self.db_file = DB_FILE
        self.db_timeout = 30.0  # æ•°æ®åº“è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        # åˆ›å»ºè¡¨ï¼šè‚¡ç¥¨æ—¥çº¿æ•°æ®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS stock_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                date TEXT NOT NULL,
                open REAL,
                close REAL,
                high REAL,
                low REAL,
                volume REAL,
                amount REAL,
                amplitude REAL,
                pct_change REAL,
                change REAL,
                turnover_rate REAL,
                UNIQUE(symbol, date)
            )
        ''')

        # åˆ›å»ºè¡¨ï¼šæ›´æ–°è®°å½•
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS update_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                last_update TEXT,
                last_date TEXT,
                record_count INTEGER
            )
        ''')

        conn.commit()
        conn.close()

    def get_data_from_cache(self, symbol: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """ä»æœ¬åœ°ç¼“å­˜è·å–æ•°æ®"""
        if start_date is None:
            start_date = START_DATE
        if end_date is None:
            end_date = END_DATE

        # è½¬æ¢æ—¥æœŸæ ¼å¼ä» YYYYMMDD åˆ° YYYY-MM-DDï¼ˆç”¨äºæ•°æ®åº“æŸ¥è¯¢ï¼‰
        def convert_date_format(date_str: str) -> str:
            """å°† YYYYMMDD æ ¼å¼è½¬æ¢ä¸º YYYY-MM-DD æ ¼å¼"""
            if len(date_str) == 8 and date_str.isdigit():
                return f"{date_str[0:4]}-{date_str[4:6]}-{date_str[6:8]}"
            return date_str  # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼

        start_date = convert_date_format(start_date)
        end_date = convert_date_format(end_date)

        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        query = f'''
            SELECT * FROM stock_data
            WHERE symbol = ? AND date >= ? AND date <= ?
            ORDER BY date
        '''

        df = pd.read_sql_query(query, conn, params=(symbol, start_date, end_date))
        conn.close()

        if df.empty:
            return None

        # è½¬æ¢æ•°æ®ç±»å‹ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
        try:
            # ä½¿ç”¨ errors='coerce' å°†æ— æ•ˆæ—¥æœŸè½¬æ¢ä¸º NaTï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            df['date'] = pd.to_datetime(df['date'], errors='coerce')

            # åˆ é™¤æ—¥æœŸè§£æå¤±è´¥çš„è¡Œ
            invalid_count = df['date'].isna().sum()
            if invalid_count > 0:
                print(f"è­¦å‘Š: {symbol} æœ‰ {invalid_count} æ¡è®°å½•çš„æ—¥æœŸæ— æ•ˆï¼Œå·²åˆ é™¤")
                df = df.dropna(subset=['date'])

            if df.empty:
                print(f"é”™è¯¯: {symbol} æ‰€æœ‰è®°å½•çš„æ—¥æœŸéƒ½æ— æ•ˆ")
                return None

        except Exception as e:
            print(f"é”™è¯¯: {symbol} æ—¥æœŸè½¬æ¢å¤±è´¥ - {e}")
            return None

        df = df.rename(columns={'date': 'æ—¥æœŸ', 'close': 'æ”¶ç›˜', 'open': 'å¼€ç›˜',
                                'high': 'é«˜', 'low': 'ä½', 'volume': 'æˆäº¤é‡',
                                'amount': 'æˆäº¤é¢', 'amplitude': 'æŒ¯å¹…',
                                'pct_change': 'æ¶¨è·Œå¹…', 'change': 'æ¶¨è·Œ',
                                'turnover_rate': 'æ¢æ‰‹ç‡'})

        return df

    def save_data_to_cache(self, symbol: str, df: pd.DataFrame):
        """å°†æ•°æ®ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜"""
        if df is None or df.empty:
            return False

        df = df.copy()

        # æ ‡å‡†åŒ–åˆ—å
        rename_map = {
            'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
            'é«˜': 'high', 'ä½': 'low', 'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
            'æ¶¨è·Œå¹…': 'pct_change', 'æ¶¨è·Œ': 'change', 'æ¢æ‰‹ç‡': 'turnover_rate'
        }

        for old, new in rename_map.items():
            if old in df.columns:
                df = df.rename(columns={old: new})

        # è½¬æ¢æ—¥æœŸæ ¼å¼ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
        try:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')

            # åˆ é™¤æ—¥æœŸæ— æ•ˆçš„è¡Œ
            invalid_count = df['date'].isna().sum()
            if invalid_count > 0:
                print(f"è­¦å‘Š: {symbol} å‡†å¤‡ä¿å­˜çš„æ•°æ®ä¸­æœ‰ {invalid_count} æ¡æ—¥æœŸæ— æ•ˆï¼Œå·²åˆ é™¤")
                df = df.dropna(subset=['date'])

            if df.empty:
                print(f"é”™è¯¯: {symbol} æ²¡æœ‰æœ‰æ•ˆçš„æ—¥æœŸæ•°æ®ï¼Œå–æ¶ˆä¿å­˜")
                return False

            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            df['date'] = df['date'].dt.strftime('%Y-%m-%d')
        except Exception as e:
            print(f"é”™è¯¯: {symbol} æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥ - {e}")
            return False

        # æ·»åŠ symbolåˆ—
        df['symbol'] = symbol

        # æå–éœ€è¦çš„åˆ—ï¼ˆæŒ‰ç…§æ•°æ®åº“è¡¨çš„é¡ºåºï¼‰
        cols_to_keep = ['symbol', 'date', 'open', 'close', 'high', 'low', 'volume', 'amount',
                        'amplitude', 'pct_change', 'change', 'turnover_rate']
        available_cols = [col for col in cols_to_keep if col in df.columns]

        # å¡«å……ç¼ºå¤±åˆ—ä¸ºNone
        for col in cols_to_keep:
            if col not in df.columns:
                df[col] = None

        df = df[cols_to_keep]

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
        max_retries = 3
        retry_delay = 1  # ç§’

        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
                cursor = conn.cursor()

                # é€è¡Œæ’å…¥ä»¥å¤„ç†UNIQUEçº¦æŸ
                for _, row in df.iterrows():
                    cursor.execute('''
                        INSERT OR IGNORE INTO stock_data
                        (symbol, date, open, close, high, low, volume, amount, amplitude, pct_change, change, turnover_rate)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', tuple(row))

                conn.commit()

                # æ›´æ–°æ—¥å¿—
                last_date = df['date'].max() if len(df) > 0 else None
                self._update_log(symbol, len(df), last_date)

                print(f"âœ“ {symbol}: å·²ä¿å­˜ {len(df)} æ¡æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜")
                conn.close()
                return True

            except sqlite3.OperationalError as e:
                # æ•°æ®åº“é”é”™è¯¯ï¼Œè¿›è¡Œé‡è¯•
                if "locked" in str(e).lower() and attempt < max_retries - 1:
                    print(f"âš ï¸  {symbol}: æ•°æ®åº“è¢«é”å®šï¼Œ{retry_delay}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    try:
                        conn.rollback()
                        conn.close()
                    except:
                        pass
                    continue
                else:
                    print(f"âœ— {symbol}: ä¿å­˜å¤±è´¥ - {e}")
                    try:
                        conn.rollback()
                        conn.close()
                    except:
                        pass
                    return False

            except Exception as e:
                print(f"âœ— {symbol}: ä¿å­˜å¤±è´¥ - {e}")
                try:
                    conn.rollback()
                    conn.close()
                except:
                    pass
                return False

        return False

    def _update_log(self, symbol: str, count: int, last_date: str = None):
        """æ›´æ–°æ—¥å¿—è¡¨"""
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO update_log (symbol, last_update, last_date, record_count)
            VALUES (?, ?, ?, ?)
        ''', (symbol, datetime.now().isoformat(), last_date, count))

        conn.commit()
        conn.close()

    def _need_daily_update(self, symbol: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ¯æ—¥æ›´æ–°

        è§„åˆ™ï¼šå¦‚æœä»Šå¤©è¿˜æ²¡æœ‰æ›´æ–°è¿‡ï¼Œè¿”å›True
        """
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        try:
            cursor.execute('''
                SELECT last_update FROM update_log WHERE symbol = ?
            ''', (symbol,))
            result = cursor.fetchone()

            if result is None:
                # æ²¡æœ‰æ›´æ–°è®°å½•ï¼Œéœ€è¦æ›´æ–°
                return True

            last_update_str = result[0]
            if last_update_str:
                # è§£ææœ€åæ›´æ–°æ—¶é—´
                last_update = datetime.fromisoformat(last_update_str)
                today = datetime.now().date()

                # å¦‚æœæœ€åæ›´æ–°ä¸æ˜¯ä»Šå¤©ï¼Œéœ€è¦æ›´æ–°
                return last_update.date() < today
            else:
                return True

        except Exception as e:
            print(f"æ£€æŸ¥æ›´æ–°çŠ¶æ€å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶ä¿å®ˆåœ°é€‰æ‹©æ›´æ–°
        finally:
            conn.close()

    def fetch_and_cache(self, symbol: str, start_date: str = None, end_date: str = None,
                       force_refresh: bool = False, daily_update: bool = True) -> pd.DataFrame:
        """
        è·å–æ•°æ®å¹¶ç¼“å­˜

        ä¼˜å…ˆç­–ç•¥ï¼š
        1. å¦‚æœ force_refresh=Trueï¼Œå¼ºåˆ¶ä»ç½‘ç»œè·å–
        2. å¦‚æœ daily_update=Trueï¼ˆé»˜è®¤ï¼‰ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ¯æ—¥é¦–æ¬¡æ›´æ–°
        3. å¦‚æœæœ¬åœ°æœ‰ç¼“å­˜ä¸”ä¸éœ€è¦æ›´æ–°ï¼Œä½¿ç”¨ç¼“å­˜
        4. å¦‚æœæœ¬åœ°æ— ç¼“å­˜æˆ–éœ€è¦æ›´æ–°ï¼Œä»ç½‘ç»œè·å–å¹¶ä¿å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            force_refresh: å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            daily_update: å¯ç”¨æ¯æ—¥é¦–æ¬¡æ›´æ–°æ£€æŸ¥
        """
        if start_date is None:
            start_date = START_DATE
        if end_date is None:
            end_date = END_DATE

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        should_update = force_refresh or (daily_update and self._need_daily_update(symbol))

        # å°è¯•ä»ç¼“å­˜è·å–
        if not should_update:
            cached_df = self.get_data_from_cache(symbol, start_date, end_date)
            if cached_df is not None and len(cached_df) > 0:
                print(f"âœ“ {symbol}: ä»æœ¬åœ°ç¼“å­˜è¯»å– {len(cached_df)} æ¡æ•°æ®ï¼ˆä»Šæ—¥å·²æ›´æ–°ï¼‰")
                return cached_df

        # ä»ç½‘ç»œè·å–
        update_reason = "å¼ºåˆ¶åˆ·æ–°" if force_refresh else "æ¯æ—¥é¦–æ¬¡æ›´æ–°"
        print(f"â³ {symbol}: æ­£åœ¨ä»ç½‘ç»œè·å–æ•°æ®...ï¼ˆ{update_reason}ï¼‰")
        df = get_stock_data(symbol, start_date, end_date)

        if df is not None and len(df) > 0:
            self.save_data_to_cache(symbol, df)
            return df
        else:
            print(f"âœ— {symbol}: æ— æ³•è·å–æ•°æ®ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜")
            # å¦‚æœç½‘ç»œè·å–å¤±è´¥ï¼Œå°è¯•è¿”å›ç¼“å­˜æ•°æ®
            cached_df = self.get_data_from_cache(symbol, start_date, end_date)
            return cached_df

    def batch_fetch_and_cache(self, symbols: list, start_date: str = None,
                             end_date: str = None, force_refresh: bool = False) -> dict:
        """æ‰¹é‡è·å–å’Œç¼“å­˜æ•°æ®"""
        all_data = {}
        failed = []

        for symbol in symbols:
            df = self.fetch_and_cache(symbol, start_date, end_date, force_refresh)
            if df is not None and len(df) > 0:
                all_data[symbol] = df
            else:
                failed.append(symbol)

        print(f"\nğŸ“Š æ‰¹é‡è·å–ç»“æœ: æˆåŠŸ {len(all_data)}, å¤±è´¥ {len(failed)}")
        return all_data

    def update_single_stock(self, symbol: str) -> bool:
        """æ›´æ–°å•åªè‚¡ç¥¨çš„æ•°æ®ï¼ˆå¢é‡æ›´æ–°ï¼‰"""
        # è·å–æœ¬åœ°æœ€æ–°æ—¥æœŸ
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()
        cursor.execute('SELECT MAX(date) FROM stock_data WHERE symbol = ?', (symbol,))
        result = cursor.fetchone()
        conn.close()

        if result[0]:
            # ä»æœ€åä¸€ä¸ªæ—¥æœŸä¹‹åç»§ç»­è·å–
            last_date = datetime.strptime(result[0], '%Y-%m-%d')
            new_start_date = (last_date + timedelta(days=1)).strftime('%Y%m%d')
        else:
            # é¦–æ¬¡è·å–
            new_start_date = START_DATE

        new_end_date = END_DATE

        print(f"ğŸ“… {symbol}: ä» {new_start_date} æ›´æ–°åˆ° {new_end_date}")

        # è·å–æ–°æ•°æ®
        df = get_stock_data(symbol, new_start_date, new_end_date)

        if df is not None and len(df) > 0:
            self.save_data_to_cache(symbol, df)
            return True
        else:
            print(f"âš ï¸  {symbol}: æ— æ–°æ•°æ®éœ€è¦æ›´æ–°")
            return False

    def get_all_cached_stocks(self) -> list:
        """è·å–æ‰€æœ‰å·²ç¼“å­˜çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        # è·å–æ‰€æœ‰ä¸åŒçš„è‚¡ç¥¨ä»£ç 
        cursor.execute('SELECT DISTINCT symbol FROM stock_data ORDER BY symbol')
        stocks = cursor.fetchall()

        conn.close()

        return [stock[0] for stock in stocks]

    def get_cache_status(self) -> dict:
        """è·å–ç¼“å­˜çŠ¶æ€"""
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        # è·å–æ€»æ•°æ®é‡
        cursor.execute('SELECT COUNT(*) FROM stock_data')
        total_records = cursor.fetchone()[0]

        # è·å–æ›´æ–°æ—¥å¿—
        cursor.execute('SELECT symbol, last_update, last_date, record_count FROM update_log ORDER BY last_update DESC')
        logs = cursor.fetchall()

        conn.close()

        return {
            'total_records': total_records,
            'db_file': str(self.db_file),
            'db_size': os.path.getsize(self.db_file) / 1024 / 1024,  # MB
            'update_logs': [
                {
                    'symbol': log[0],
                    'last_update': log[1],
                    'last_date': log[2],
                    'record_count': log[3]
                } for log in logs
            ]
        }

    def clear_cache(self, symbol: str = None):
        """æ¸…ç©ºç¼“å­˜"""
        conn = sqlite3.connect(self.db_file, timeout=self.db_timeout)
        cursor = conn.cursor()

        if symbol:
            cursor.execute('DELETE FROM stock_data WHERE symbol = ?', (symbol,))
            cursor.execute('DELETE FROM update_log WHERE symbol = ?', (symbol,))
            print(f"âœ“ å·²æ¸…ç©º {symbol} çš„ç¼“å­˜æ•°æ®")
        else:
            cursor.execute('DELETE FROM stock_data')
            cursor.execute('DELETE FROM update_log')
            print("âœ“ å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜æ•°æ®")

        conn.commit()
        conn.close()

    def export_cache_to_csv(self, symbol: str, output_dir: str = "./data_export"):
        """å¯¼å‡ºç¼“å­˜æ•°æ®ä¸ºCSV"""
        Path(output_dir).mkdir(exist_ok=True)

        df = self.get_data_from_cache(symbol)
        if df is None or df.empty:
            print(f"âœ— {symbol}: æ— ç¼“å­˜æ•°æ®")
            return None

        output_file = Path(output_dir) / f"{symbol}_data.csv"
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"âœ“ å·²å¯¼å‡ºåˆ°: {output_file}")
        return str(output_file)


# å‘½ä»¤è¡Œå·¥å…·
if __name__ == "__main__":
    import sys

    manager = DataManager()

    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "status":
            # æŸ¥çœ‹ç¼“å­˜çŠ¶æ€
            status = manager.get_cache_status()
            print("\n" + "="*60)
            print("  æ•°æ®ç¼“å­˜çŠ¶æ€")
            print("="*60)
            print(f"æ€»æ•°æ®é‡: {status['total_records']} æ¡")
            print(f"æ•°æ®åº“æ–‡ä»¶: {status['db_file']}")
            print(f"æ•°æ®åº“å¤§å°: {status['db_size']:.2f} MB")
            print()
            print("æ›´æ–°æ—¥å¿—:")
            for log in status['update_logs']:
                print(f"  {log['symbol']}: {log['record_count']}æ¡ (æœ€åæ›´æ–°: {log['last_date']})")

        elif command == "update":
            # æ›´æ–°å•åªè‚¡ç¥¨
            if len(sys.argv) > 2:
                symbol = sys.argv[2]
                manager.update_single_stock(symbol)
            else:
                print("ç”¨æ³•: python data_manager.py update <symbol>")

        elif command == "clear":
            # æ¸…ç©ºç¼“å­˜
            if len(sys.argv) > 2:
                symbol = sys.argv[2]
                manager.clear_cache(symbol)
            else:
                confirm = input("ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ç¼“å­˜? (yes/no): ")
                if confirm.lower() == "yes":
                    manager.clear_cache()

        elif command == "export":
            # å¯¼å‡ºæ•°æ®
            if len(sys.argv) > 2:
                symbol = sys.argv[2]
                manager.export_cache_to_csv(symbol)
            else:
                print("ç”¨æ³•: python data_manager.py export <symbol>")

        elif command == "fetch":
            # ä»ç½‘ç»œè·å–å¹¶ç¼“å­˜
            if len(sys.argv) > 2:
                symbol = sys.argv[2]
                df = manager.fetch_and_cache(symbol, force_refresh=True)
            else:
                print("ç”¨æ³•: python data_manager.py fetch <symbol>")

    else:
        print("""
æ•°æ®ç®¡ç†å·¥å…·

ç”¨æ³•:
  python data_manager.py status                    æŸ¥çœ‹ç¼“å­˜çŠ¶æ€
  python data_manager.py fetch <symbol>            è·å–å¹¶ç¼“å­˜æ•°æ®
  python data_manager.py update <symbol>           å¢é‡æ›´æ–°æ•°æ®
  python data_manager.py export <symbol>           å¯¼å‡ºä¸ºCSV
  python data_manager.py clear [symbol]            æ¸…ç©ºç¼“å­˜

ç¤ºä¾‹:
  python data_manager.py status
  python data_manager.py fetch 000001
  python data_manager.py update 000001
  python data_manager.py export 000001
  python data_manager.py clear 000001
        """)
